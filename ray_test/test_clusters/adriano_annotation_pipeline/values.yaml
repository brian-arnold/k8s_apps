image:
  # Match your client version!
  repository: registry.atlab.stanford.edu/annotation_pipeline
  tag: "latest"
  pullPolicy: Always 

head:
  priorityClassName: standard-gpu 
  enableInTreeAutoscaling: true
  autoscalerOptions:
    upscalingMode: Default
    idleTimeoutSeconds: 60
  resources:
    requests:
      cpu: "1"
      memory: "50Gi"
    limits:
      cpu: "1"
      memory: "50Gi"
  volumes:
    - name: lab-storage
      hostPath:
        path: /mnt/lab
        type: Directory
    - name: enigma-videos
      hostPath:
        path: /mnt/enigma-videos
        type: Directory
  volumeMounts:
    - name: lab-storage
      mountPath: /lab
    - name: enigma-videos
      mountPath: /enigma-videos

worker:
  priorityClassName: standard-gpu 
  replicas: 1
  minReplicas: 1
  maxReplicas: 60
  nodeSelector:
    nvidia.com/gpu.present: "true"  # or specific GPU node
  resources:
    requests:
      nvidia.com/gpu: 1
      cpu: 8
      memory: "80Gi"
    limits:
      nvidia.com/gpu: 1
      cpu: 8
      memory: "80Gi"
  volumes:
    - name: lab-storage
      hostPath:
        path: /mnt/lab
        type: Directory
    - name: enigma-videos
      hostPath:
        path: /mnt/enigma-videos
        type: Directory
  volumeMounts:
    - name: lab-storage
      mountPath: /lab
    - name: enigma-videos
      mountPath: /enigma-videos

  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: kubernetes.io/hostname
            operator: In
            values:
            # lower mem GPUs
            # - at-gpu1
            # - at-gpu2
            # - at-gpu3
            # - at-gpu5
            # higher mem GPUs
            - at-gpu4
            - at-gpu6
            - at-gpu7
            - at-gpu8
            - at-gpu9
            - at-gpu10
            - at-gpu11
            - at-gpu12
